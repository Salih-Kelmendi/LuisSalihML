from ucimlrepo import fetch_ucirepo
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# ðŸ“Œ Datensatz abrufen
def load_data():
    dataset = fetch_ucirepo(id=373)
    X = dataset.data.features
    y = dataset.data.targets

    # Entferne unerwÃ¼nschte Merkmale
    X = X.drop(columns=['ethnicity', 'gender', 'country', 'age', 'impuslive', 'ss', 'education'], errors='ignore')
    return X, y

X, y = load_data()

# ðŸ“Œ Drogenliste definieren
drug_columns = ['cannabis', 'coke', 'nicotine']

# ðŸ“Œ Daten aufteilen
def split_data(X, y_selected, test_size=0.2):
    return train_test_split(X, y_selected, test_size=test_size, random_state=42)

# ðŸ“Œ Modelle erstellen
def initialize_models():
    return {
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
        "Logistische Regression": LogisticRegression(max_iter=1000),
        "K-Nearest Neighbors": KNeighborsClassifier()
    }

# ðŸ“Œ Modelle trainieren
def train_models(models, X_train, y_train):
    for model in models.values():
        model.fit(X_train, y_train)
    return models

# ðŸ“Œ Modelle evaluieren
def evaluate_models(models, X_test, y_test, drug_name):
    for name, model in models.items():
        y_pred = model.predict(X_test)

        print(f"\n{name} - Genauigkeit fÃ¼r {drug_name.capitalize()}: {accuracy_score(y_test, y_pred)}")
        print(f"{name} - Klassifikationsbericht:\n{classification_report(y_test, y_pred, zero_division=0)}")

        # Konfusionsmatrix anzeigen
        plt.figure(figsize=(8, 6))
        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
        plt.title(f"Konfusionsmatrix - {name} ({drug_name.capitalize()})")
        plt.xlabel("Vorhergesagt")
        plt.ylabel("Wahr")
        plt.show()

# ðŸ“Œ Feature Importance (nur fÃ¼r Random Forest)
def plot_feature_importance(rf_model, X, drug_name):
    feature_importances = rf_model.feature_importances_
    importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
    importance_df = importance_df.sort_values(by='Importance', ascending=False)

    plt.figure(figsize=(10, 5))
    sns.barplot(x=importance_df['Importance'], y=importance_df['Feature'])
    plt.title(f'Feature Importance fÃ¼r {drug_name.capitalize()} (Random Forest)')
    plt.xlabel('Wichtigkeit')
    plt.ylabel('Feature')
    plt.show()

# ðŸ“Œ Inference-Funktion fÃ¼r neue Personen
def make_prediction(models, X, drug_name):
    new_sample = np.array(X.iloc[0]).reshape(1, -1)

    print(f"\n*** INFERENCE fÃ¼r {drug_name.capitalize()} ***")
    for name, model in models.items():
        prediction = model.predict(new_sample)
        print(f"Vorhersage ({name}): {prediction}")

# ðŸ“Œ ÃœberprÃ¼fung der Klassenverteilung
def check_class_distribution(y_train, y_test, drug_name):
    print(f"\nðŸ“Š Klassenverteilung fÃ¼r {drug_name.capitalize()}:")
    print("ðŸ”¹ Trainingsdaten:")
    print(y_train.value_counts())
    print("\nðŸ”¹ Testdaten:")
    print(y_test.value_counts())

    # Visualisierung der Klassenverteilung
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    sns.barplot(x=y_train.value_counts().index, y=y_train.value_counts(), ax=axes[0])
    axes[0].set_title(f'Klassenverteilung (Train) - {drug_name.capitalize()}')
    axes[0].set_xlabel('Klasse')
    axes[0].set_ylabel('Anzahl')

    sns.barplot(x=y_test.value_counts().index, y=y_test.value_counts(), ax=axes[1])
    axes[1].set_title(f'Klassenverteilung (Test) - {drug_name.capitalize()}')
    axes[1].set_xlabel('Klasse')
    axes[1].set_ylabel('Anzahl')

    plt.show()

Schreibe diesen code so, sodass keine konfusionsmatrixen angezeigt werden ,ich habe diesen code nur zum Ã¼berprÃ¼fen
